{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip\n",
        "!pip uninstall -y huggingface_hub sentence-transformers transformers langchain langchain-community langchain-text-splitters langchain-huggingface\n",
        "\n",
        "!pip install -U \\\n",
        "  langchain \\\n",
        "  langchain-community \\\n",
        "  langchain-text-splitters \\\n",
        "  langchain-huggingface \\\n",
        "  langgraph \\\n",
        "  chromadb \\\n",
        "  tiktoken\n",
        "\n",
        "!pip install -U huggingface_hub==0.23.5 sentence-transformers==2.7.0 transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P_11fnd0cle",
        "outputId": "edc940f6-95d2-4503-c405-f41bff597a0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (26.0.1)\n",
            "Found existing installation: huggingface-hub 0.23.5\n",
            "Uninstalling huggingface-hub-0.23.5:\n",
            "  Successfully uninstalled huggingface-hub-0.23.5\n",
            "Found existing installation: sentence-transformers 2.7.0\n",
            "Uninstalling sentence-transformers-2.7.0:\n",
            "  Successfully uninstalled sentence-transformers-2.7.0\n",
            "Found existing installation: transformers 4.46.3\n",
            "Uninstalling transformers-4.46.3:\n",
            "  Successfully uninstalled transformers-4.46.3\n",
            "Found existing installation: langchain 1.2.10\n",
            "Uninstalling langchain-1.2.10:\n",
            "  Successfully uninstalled langchain-1.2.10\n",
            "Found existing installation: langchain-community 0.4.1\n",
            "Uninstalling langchain-community-0.4.1:\n",
            "  Successfully uninstalled langchain-community-0.4.1\n",
            "Found existing installation: langchain-text-splitters 1.1.1\n",
            "Uninstalling langchain-text-splitters-1.1.1:\n",
            "  Successfully uninstalled langchain-text-splitters-1.1.1\n",
            "Found existing installation: langchain-huggingface 1.2.0\n",
            "Uninstalling langchain-huggingface-1.2.0:\n",
            "  Successfully uninstalled langchain-huggingface-1.2.0\n",
            "Collecting langchain\n",
            "  Using cached langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-text-splitters\n",
            "  Using cached langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Using cached langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.13.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.33.4 (from langchain-huggingface)\n",
            "  Using cached huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.41.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.24.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.51.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.78.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.24.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (35.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (0.0.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.20 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Using cached langchain-1.2.10-py3-none-any.whl (111 kB)\n",
            "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
            "Using cached langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Using cached huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "Installing collected packages: huggingface-hub, langchain-text-splitters, langchain-huggingface, langchain-community, langchain\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [langchain]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.1 requires transformers, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.36.2 langchain-1.2.10 langchain-community-0.4.1 langchain-huggingface-1.2.0 langchain-text-splitters-1.1.1\n",
            "Collecting huggingface_hub==0.23.5\n",
            "  Using cached huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting sentence-transformers==2.7.0\n",
            "  Using cached sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting transformers\n",
            "  Using cached transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.23.5) (4.15.0)\n",
            "  Using cached transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.7.0) (2.10.0+cu128)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.7.0) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.7.0) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.7.0) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.7.0) (11.3.0)\n",
            "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached transformers-4.57.5-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached transformers-4.57.4-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached transformers-4.57.2-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
            "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached transformers-4.56.0-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "  Using cached transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
            "  Using cached transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
            "  Using cached transformers-4.55.1-py3-none-any.whl.metadata (41 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
            "  Using cached transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n",
            "  Using cached transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n",
            "  Using cached transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "  Using cached transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "  Using cached transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "  Using cached transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
            "  Using cached transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
            "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers==2.7.0) (1.3.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.7.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.23.5) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.23.5) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.23.5) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.23.5) (2026.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (3.6.0)\n",
            "Using cached huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
            "Using cached sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "Using cached transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "Installing collected packages: huggingface_hub, transformers, sentence-transformers\n",
            "\u001b[2K  Attempting uninstall: huggingface_hub\n",
            "\u001b[2K    Found existing installation: huggingface_hub 0.36.2\n",
            "\u001b[2K    Uninstalling huggingface_hub-0.36.2:\n",
            "\u001b[2K      Successfully uninstalled huggingface_hub-0.36.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [sentence-transformers]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-huggingface 1.2.0 requires huggingface-hub<1.0.0,>=0.33.4, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "peft 0.18.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "gradio 5.50.0 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.23.5 sentence-transformers-2.7.0 transformers-4.46.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install cassio"
      ],
      "metadata": {
        "id": "JdtgzvkRDktt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cassio\n",
        "from google.colab import userdata\n",
        "\n",
        "ASTRA_DB_TOKEN = userdata.get(\"ASTRA_DB_TOKEN\")\n",
        "ASTRA_DB_ID = userdata.get(\"ASTRA_DB_ID\")\n",
        "\n",
        "if not ASTRA_DB_TOKEN or not ASTRA_DB_ID:\n",
        "    raise ValueError(\"Set ASTRA_DB_APPLICATION_TOKEN and ASTRA_DB_ID in Colab Secrets\")\n",
        "\n",
        "cassio.init(token=ASTRA_DB_TOKEN, database_id=ASTRA_DB_ID)"
      ],
      "metadata": {
        "id": "vZK6v-QYLGhf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=500, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgWJWGWaMZhM",
        "outputId": "f6b144fd-0517-43a2-bf9a-47ffe4dbdeff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "mgFv8Wrh0zWm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Cassandra\n",
        "\n",
        "astra_vector_store=Cassandra(\n",
        "    embedding=embeddings,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "MYwixlyW2zZ1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_documents(doc_splits)\n",
        "print(\"Inserted %i chunks.\" % len(doc_splits))\n",
        "\n",
        "retriever = astra_vector_store.as_retriever(search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmxorr-K3jUg",
        "outputId": "a7a2283e-ac3f-426e-bfa5-52c1900b2b79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 88 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=astra_vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "c_G1Cw2s4NmO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"What is agent\",ConsistencyLevel=\"LOCAL_ONE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkBS95yt4OeK",
        "outputId": "0d0eee42-ca32-4c11-9de9-3be9287785f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='427e6227557040e3a4c646fc940cab3f', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
              " Document(id='feede64155f848f0884919d92b54d175', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
              " Document(id='e549cf849afd4deeb5009ad02a0f509f', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
              " Document(id='25ca981ca1a44c6d886e3baeba6fca17', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "RSxu_rT-Cwrw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
        "\n",
        "    datasource: Literal[\"vectorstore\", \"wiki_search\"] = Field(\n",
        "        ...,\n",
        "        description=\"Given a user question choose to route it to wikipedia or a vectorstore.\",\n",
        "    )"
      ],
      "metadata": {
        "id": "h_lWTsnFC2eO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain_groq"
      ],
      "metadata": {
        "id": "VmdxSWdVD7-c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "\n",
        "groq_api_key=userdata.get('groq_api_key')\n",
        "os.environ[\"GROQ_API_KEY\"]=groq_api_key\n",
        "\n",
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama-3.3-70b-Versatile\")\n",
        "\n",
        "structured_llm_router = llm.with_structured_output(RouteQuery)"
      ],
      "metadata": {
        "id": "70HlPZuGDG7X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"\"\"You are an expert at routing a user question to a vectorstore or wikipedia.\n",
        "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
        "Use the vectorstore for questions on these topics. Otherwise, use wiki-search.\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_router = route_prompt | structured_llm_router"
      ],
      "metadata": {
        "id": "nwzGJ3X7EpQA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    question_router.invoke(\n",
        "        {\"question\": \"who is Sharukh Khan?\"}\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLKd1vIgGjjP",
        "outputId": "927096c1-ada6-4cb3-ed2a-eb77b023ede1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='wiki_search'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    question_router.invoke(\n",
        "        {\"question\": \"who is RAG?\"}\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKhWmieHHJ21",
        "outputId": "991e9ed9-9e73-4231-9292-72a27fc7a633"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='vectorstore'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain_community\n",
        "!pip -q install wikipedia"
      ],
      "metadata": {
        "id": "5la-nzcsJNnc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "\n",
        "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
        "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
      ],
      "metadata": {
        "id": "myC0-hJMJRGT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[str]"
      ],
      "metadata": {
        "id": "BiXbrzCOJerM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}"
      ],
      "metadata": {
        "id": "GmIXVhUevdNG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wiki_search(state):\n",
        "    \"\"\"\n",
        "    wiki search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---wikipedia---\")\n",
        "    question = state[\"question\"]\n",
        "    print(question)\n",
        "\n",
        "    docs = wiki.invoke({\"query\": question})\n",
        "    wiki_results = docs\n",
        "    wiki_results = Document(page_content=wiki_results)\n",
        "\n",
        "    return {\"documents\": wiki_results, \"question\": question}"
      ],
      "metadata": {
        "id": "aYAlZ5-VwImK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to wiki search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"wiki_search\":\n",
        "        print(\"---ROUTE QUESTION TO Wiki SEARCH---\")\n",
        "        return \"wiki_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\""
      ],
      "metadata": {
        "id": "8EeUZbGUw0yp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "workflow.add_node(\"wiki_search\", wiki_search)   # web search\n",
        "workflow.add_node(\"retrieve\", retrieve)   # retrieve\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"wiki_search\": \"wiki_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge( \"retrieve\", END)\n",
        "workflow.add_edge( \"wiki_search\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw95GED90KeZ",
        "outputId": "b9d39aa8-e232-4d19-b343-6c9ccf76165d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7840e40f40e0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "AZFgeJQH0QIU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "ZlvBh8dn0UnP",
        "outputId": "27a50a68-6d1e-488c-f981-028a97042f5d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "inputs = {\n",
        "    \"question\": \"What is agent?\"\n",
        "}\n",
        "\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        print(f\"Node '{key}':\")\n",
        "        pprint(value, indent=2, width=80, depth=None)\n",
        "        print(\"\\n---\\n\")\n",
        "\n",
        "if \"documents\" in value and len(value[\"documents\"]) > 0:\n",
        "    print(value[\"documents\"][0].metadata.get(\"description\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1CrgJT22wHI",
        "outputId": "7eb07d12-8bef-4ef6-b4ce-a9650b6b01ff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO RAG---\n",
            "---RETRIEVE---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 'retrieve':\n",
            "{ 'documents': [ Document(id='427e6227557040e3a4c646fc940cab3f', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
            "                 Document(id='feede64155f848f0884919d92b54d175', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
            "                 Document(id='e549cf849afd4deeb5009ad02a0f509f', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
            "                 Document(id='25ca981ca1a44c6d886e3baeba6fca17', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.')],\n",
            "  'question': 'What is agent?'}\n",
            "\n",
            "---\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview\n",
            "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
            "\n",
            "Planning\n",
            "\n",
            "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
            "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
            "\n",
            "\n",
            "Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
            "\n",
            "\n",
            "Tool use\n",
            "\n",
            "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\n",
            "\tOverview of a LLM-powered autonomous agent system.\n",
            "\n",
            "Component One: Planning\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "inputs = {\n",
        "    \"question\": \"Prabhas\"\n",
        "}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"Node '{key}':\")\n",
        "\n",
        "pprint(value['documents'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6P4q3u40V5n",
        "outputId": "8076c0e2-8296-42f6-b9e9-eacaba20ba2d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO Wiki SEARCH---\n",
            "---wikipedia---\n",
            "Prabhas\n",
            "\"Node 'wiki_search':\"\n",
            "Document(metadata={}, page_content='Page: Prabhas\\nSummary: Uppalapati Venkata Suryanarayana Prabhas Raju  ([pɾabʱaːs]; born 23 October 1979), known mononymously as Prabhas, is an Indian actor who predominantly works in Telugu cinema. He')\n"
          ]
        }
      ]
    }
  ]
}